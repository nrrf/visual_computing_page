[{"id":0,"href":"/visual_computing_page/docs/shortcodes/euler_angles/","title":"Euler Angles","section":"Shortcodes","content":" Angulos de euler # Son un conjunto de tres ángulos, alfa, beta y gamma, que permiten describir la orientación de un sólido de una forma más detallada, es decir se aplicaran cambios de referencia alfa, betta, gamma, sobre el resultado de referencia anterior. Por lo que se deben multiplicar las matrices del cambio de orientación.\nExisten 3 cambios de orientación de los cuales por regla general, los 3 no pueden ser ejecutados en el mismo eje, sino que por regla general, el primero y el último se suelen aplicar sobre el mismo eje, y el segundo giro se aplica sobre un eje perpendicular al eje de giro.\nDebido a que existen múltiples casos, vamos a ver los ángulos de Euler donde se gira respecto al eje z, un ángulo alfa, un ángulo gamma respecto al eje Z, y un ángulo beta respecto al eje x.\nConociendo los valores de la matriz del cambio de orientación, vamos a calcular los valores de cada uno de los ángulos de Euler.\nLa siguiente matriz, es la matriz de orientación de la secuencia de giro ZXZ, con sus correspondientes ángulos alfa, beta, gamma.\n\\[ R = \\begin{bmatrix} cos_\\alpha cos_\\gamma -sen_\\alpha cos_\\beta sen_\\gamma \u0026amp; -cos_\\alpha sen_\\gamma -sen_\\alpha cos_\\beta cos_\\gamma \u0026amp; sen_\\alpha sen_\\beta \\\\ sen_\\alpha cos_\\gamma \u0026#43; cos_\\alpha cos_\\beta sen_\\gamma \u0026amp; -sen_\\alpha sen_\\gamma \u0026#43;cos_\\alpha cos_\\beta cos_\\gamma \u0026amp; -cos_\\alpha sen_\\beta \\\\ sen_\\beta sen_\\gamma \u0026amp; sen_\\beta cos_\\gamma \u0026amp; cos_\\beta \\\\ \\end{bmatrix} \\] Generalizando la matriz de rotación, se tiene la siguiente forma: \\[R = \\begin{bmatrix} r_1_1 \u0026amp; r_1_2 \u0026amp; r_1_3 \\\\ r_2_1 \u0026amp; r_2_2 \u0026amp; r_2_3 \\\\ r_3_1 \u0026amp; r_3_2 \u0026amp; r_3_3 \\\\ \\end{bmatrix} \\] Dada la matriz de rotación R, podemos calcular el valor de los ángulos de Euler: Empezamos elevando el cuadrado a r_31 y r_32, sacando el factor común de la ecuación, teniendo en cuenta sen^2 y cos^2 es igual a 1. \\[ r^{2}_{31} \u0026#43; r^{2}_{32} = sen^{2}_{\\beta}sen^{2}_{\\gamma } \u0026#43; sen^{2}_{\\beta}cos^{2}_{\\gamma } = sen^{2}_{\\beta}(sen^{2}_{\\gamma } \u0026#43; cos^{2}_{\\gamma } ) = sen^{2}_{\\beta} \\] Ahora despejamos el cuadrado, obteniendo dos posibles soluciones: \\[ sen_{\\beta } = \\sqrt{r_{31}^{2} \u0026#43; r_{32}^{2}} \\] \\[ sen_{\\beta } = -\\sqrt{r_{31}^{2} \u0026#43; r_{32}^{2}}\\] Teniendo en cuenta la primera solución, y conociendo que r_33 es coseno de Beta, se tiene que: \\[ tan_{\\beta } = \\left ( \\frac{\\sqrt{r_{31}^{2} \u0026#43; r_{32}^{2}}}{r_{33}} \\right ) \\] Y despejando Beta, y conociendo que Beta está entre 0 y pi, tenemos que: \\[ \\beta = tan^{-1}\\left ( \\frac{\\sqrt{r_{31}^{2} \u0026#43; r_{32}^{2}}}{r_{33}} \\right ) \\] Ahora calculamos el valor del ángulo gamma dividiendo r_31 y r_32: \\[ \\frac{r_{31}}{r_{32}} = \\frac{sen_\\beta sen_\\gamma }{sen_\\beta cos_\\gamma } = \\frac{sen_\\gamma }{cos_\\gamma } = tan_\\gamma \\] Despejamos Gamma, y tenemos el siguiente resultado: \\[ \\gamma = tan^{-1}\\left ( \\frac{r_{31}}{r_{32}} \\right ) \\] Ahora vamos a calcular el valor del ángulo alfa, teniendo en cuenta r_13 y r_23: \\[ \\frac{r_{13}}{r_{23}} = \\frac{sen_\\alpha sen_\\beta }{-cos_\\alpha sen_\\beta } = \\frac{sen_\\alpha }{-cos_\\alpha } = tan_\\alpha \\] Despejamos alfa, y tenemos el siguiente resultado: \\[ \\alpha = tan^{-1}\\left ( \\frac{r_{13}}{-r_{23}} \\right ) \\] De esta manera, tenemos el resultado de los tres ángulos, para ángulos entre 0 y pi.\nAhora bien, al tener en cuenta la parte negativa del despeje del cuadrado, es decir el valor de beta está entre pi y 2pi, y conociendo que coseno de Beta es r_33, tenemos que el ángulo Beta es: \\[ \\beta = tan^{-1}\\left ( \\frac{-\\sqrt{r_{31}^{2} \u0026#43; r_{32}^{2}}}{r_{33}} \\right ) \\] Ahora calculamos el ángulo gamma: \\[ \\frac{-r_{31}}{-r_{32}} = \\frac{sen_\\beta sen_\\gamma }{sen_\\beta cos_\\gamma } = \\frac{sen_\\gamma }{cos_\\gamma } = tan_\\gamma \\] \\[ \\gamma = tan^{-1}\\left ( \\frac{-r_{31}}{-r_{32}} \\right ) \\] Y por el último calculamos el ángulo alfa: \\[ \\frac{-r_{13}}{r_{23}} = \\frac{-sen_\\alpha sen_\\beta }{cos_\\alpha sen_\\beta } = \\frac{-sen_\\alpha }{cos_\\alpha } = tan_\\alpha \\] \\[ \\alpha = tan^{-1}\\left ( \\frac{-r_{13}}{r_{23}} \\right ) \\] Y de esta manera, tenemos los valores para los ángulos entre pi y 2 pi.\n"},{"id":1,"href":"/visual_computing_page/docs/shortcodes/ilusiones/","title":"Ilusiones","section":"Shortcodes","content":" Ilusiones # \u0026lsquo;Tienes que crear confusión sistemáticamente, libera la creatividad. Todo lo que es contradictorio crea vida\u0026rsquo;, Salvador Dalli\nPenrose Triangle # Historia # El triángulo de Penrose fue creado por primera vez en 1934 por el pintor sueco Oscar Reutersvärd. Dibujó su versión de triángulo como un conjunto de cubos en proyección paralela. Aunque muchos pintores utilizaron triángulos imposibles en su arte, Oscar Reutersvärd abrió el mundo fantástico de las figuras imposibles. Creó miles de figuras imposibles para su vida y ahora se lo conoce como el \u0026ldquo;padre\u0026rdquo; de las figuras imposibles. En 1980, el gobierno sueco decidió colocar un triángulo imposible y otras dos figuras suyas en los sellos postales, que se imprimieron alrededor de dos años.\nEn 1954, el matemático inglés Roger Penrose después de la lección del artista holandés M.C. Escher dibujó un triángulo imposible en su vista común. A diferencia del triángulo de Reutersvärd, pintó el triángulo como tres barras conectadas con ángulos rectos. Le dio un efecto de perspectiva, lo que aumentó el efecto de imposibilidad. Publicó su versión del triángulo en la revista British Psychology en 1954 en un artículo conjunto de él y su padre Lionel Penrose.\nMucha gente piensa que el triángulo de Penrose es realmente imposible y no se puede construir en el mundo real. Pero se demostró que todas las figuras imposibles son posibles de realizar. Es posible crear objetos tridimensionales que parezcan imposibles desde un único punto de vista y parezcan normales desde todos los demás puntos de vista. Un ejemplo de esta obra en la vida real, se encuentra en Australia, la cual es visitada por miles de turistas.\n¿Por qué el triángulo de Penrose también es conocido como el triángulo imposible? # Imposible porque aparenta ser un objeto sólido conformado por tres tramos rectos interconectados en los extremos del triángulo formando ángulos rectos, cosa que dentro de un espacio euclídeo ordinario no es posible la combinación de estas propiedades (aunque sí podría cumplirse dentro del espacio 3-variedad, campo el cual estudia variedades topológicas de tres dimensiones).\nEstas y más son las razones del porqué su efecto visual causa gran impresión dentro de esta rama, y se ha catalogado como una de las ‘figuras imposibles’ que quedan definidas en imágenes de dos dimensiones, a las cuales se les agregan efectos para que luzcan imposibles tridimensionalmente. Pueden tener sentido dentro del plano 2D, pero no en el espacio 3D, por eso se denomina –según el investigador Abrahan Tamir en su estudio “geometría posible en 2D pero imposible en 3D” figura imposible al triángulo de Penrose.\nPenrose Triangle 2D # Code ... function setup() { createCanvas(400, 400); } function draw() { background(0); stroke(175) noFill() strokeWeight(4) beginShape() vertex(187,100) vertex(100,217) vertex(118,235) vertex(281,235) vertex(292,217) vertex(209,100) vertex(188,100) vertex(255,198) vertex(223,198) //stroke(175) vertex(170,198) vertex(197,162) vertex(224,198) vertex(185,145) vertex(118,235) endShape() beginShape() vertex(170,198) vertex(157,217) vertex(292,217) endShape() } Penrose Triangle 3D # Code ... //penrose_triangle.js let sf = 1; // scaleFactor let locked = true; function setup() { sliderx = createSlider(0, 10, 10, 0.1); sliderx.position(30, 30); slidery = createSlider(0, 10, 3.6, 0.1); slidery.position(30, 55); sliderz = createSlider(0, 10, 8.1, 0.1); sliderz.position(30, 80); createCanvas(700, 700, WEBGL); fill(237, 34, 93); cuboid1 = new Cuboid(0, 180, 0, 30, 0, 30); cuboid2 = new Cuboid(0, 30, 0, 30, 180); cuboid3 = new Cuboid(0, 30, 0, 120, 150, 30); } function draw() { scale(sf); background(200); rotateX(sliderx.value()); rotateY(slidery.value()); rotateZ(sliderz.value()); // first cuboid cuboid1.draw() //second cuboid cuboid2.draw() //third cuboid cuboid3.draw() } class Cuboid { constructor(x, w, y, h, z, d) { this.x = x this.w = w this.y = y this.h = h this.z = z this.d = d } draw() { beginShape(); vertex(this.x, this.y, this.z); vertex(this.x + this.w, this.y, this.z); vertex(this.x + this.w, this.y + this.h, this.z); vertex(this.x, this.y + this.h, this.z); endShape(CLOSE); beginShape(); vertex(this.x, this.y, this.z + this.d); vertex(this.x + this.w, this.y, this.z + this.d); vertex(this.x + this.w, this.y + this.h, this.z + this.d); vertex(this.x, this.y + this.h, this.z + this.d); endShape(CLOSE); beginShape(); vertex(this.x + this.w, this.y, this.z); vertex(this.x, this.y, this.z); vertex(this.x, this.y, this.z + this.d); vertex(this.x + this.w, this.y, this.z + this.d); endShape(CLOSE); beginShape(); vertex(this.x, this.y + this.h, this.z); vertex(this.x + this.w, this.y + this.h, this.z); vertex(this.x + this.w, this.y + this.h, this.z + this.d); vertex(this.x, this.y + this.h, this.z + this.d); endShape(CLOSE); beginShape(); vertex(this.x, this.y, this.z); vertex(this.x, this.y, this.z + this.d); vertex(this.x, this.y + this.h, this.z + this.d); vertex(this.x, this.y + this.h, this.z); endShape(CLOSE); beginShape(); vertex(this.x + this.w, this.y, this.z); vertex(this.x + this.w, this.y, this.z + this.d); vertex(this.x + this.w, this.y + this.h, this.z + this.d); vertex(this.x + this.w, this.y + this.h, this.z); endShape(CLOSE); } } function mousePressed() { locked = false } function mouseClicked() { //console.log(\u0026#39;Released\u0026#39;) locked = true } function mouseWheel(event) { if (locked != true) { if (event.deltaY \u0026lt; 0) sf *= 1.05; else sf *= 0.95; } } Penrose Staircase # Code ... function setup() { sliderx = createSlider(4, 7, 5.25, 0.01); sliderx.position(30, 30); slidery = createSlider(4, 7, 5.27, 0.01); slidery.position(30, 55); sliderz = createSlider(0, 10, 0, 0.01); sliderz.position(30, 80); createCanvas(700, 700, WEBGL); fill(237, 34, 93); // cuboid1 = new Cuboid(0, 50, 0, -(200 / 13) * 9, 0, 50); cuboid2 = new Cuboid(50, 50, 0, -(200 / 13) * 10, 0, 50); cuboid3 = new Cuboid(100, 50, 0, -(200 / 13) * 11, 0, 50); cuboid4 = new Cuboid(150, 50, 0, -(200 / 13) * 12, 0, 50); cuboid5 = new Cuboid(200, 50, 0, -(200 / 13) * 13, 0, 50); // cuboid6 = new Cuboid(0, 50, 0, -(200 / 13) * 8, 0, -50); cuboid7 = new Cuboid(0, 50, (200 / 13) * 5, -(200 / 13) * 12, -50, -50); cuboid8 = new Cuboid(0, 50, (200 / 13) * 5, -(200 / 13) * 11, -100, -50); // cuboid9 = new Cuboid(200, 50, 0, -(200 / 13) * 14, 0, -50); cuboid10 = new Cuboid(200, 50, 0, -(200 / 13) * 15, -50, -50); // cuboid11 = new Cuboid(150, 50, 0, -(200 / 13) * 16, -50, -50); //cuboid12 = new Cuboid(100, 50, -(200/13)*17, -(200/13)*1, -50, -50); } function draw() { scale(0.5); background(200); rotateX(sliderx.value()); rotateY(slidery.value()); rotateZ(sliderz.value()); //console.log(sliderx.value()); //console.log(slidery.value()) //orbitControl() // first cuboid cuboid1.draw() cuboid2.draw() cuboid3.draw() cuboid4.draw() cuboid5.draw() cuboid6.draw() cuboid7.draw() cuboid8.draw() cuboid9.draw() cuboid10.draw() cuboid11.draw() // frente // push son para modificar el estilo y no afectar el resto de la plantilla push() noStroke() beginShape(); vertex(100, -(200 / 13) * 16, -50 - (200 / 13) * 2); vertex(150, -(200 / 13) * 16, -50 - (200 / 13) * 2); vertex(150, -(200 / 13) * 17, -50 - (200 / 13) * 1); vertex(100, -(200 / 13) * 17, -50 - (200 / 13) * 1); endShape(CLOSE); beginShape(); vertex(100, -(200 / 13) * 16, -100); vertex(150, -(200 / 13) * 16, -100); vertex(150, -(200 / 13) * 17, -100); vertex(100, -(200 / 13) * 17, -100); endShape(CLOSE); pop() //inferior beginShape(); vertex(150, -(200 / 13) * 16, -50 - (200 / 13) * 2); vertex(100, -(200 / 13) * 16, -50 - (200 / 13) * 2); vertex(100, -(200 / 13) * 16, -100); vertex(150, -(200 / 13) * 16, -100); endShape(CLOSE); //superior push() noStroke() beginShape(); vertex(100, -(200 / 13) * 17, -50 - (200 / 13) * 1); vertex(150, -(200 / 13) * 17, -50 - (200 / 13) * 1); vertex(150, -(200 / 13) * 17, -100); vertex(100, -(200 / 13) * 17, -100); endShape(CLOSE); pop() // frente izq beginShape(); vertex(100, -(200 / 13) * 16, -50 - (200 / 13) * 2); vertex(100, -(200 / 13) * 16, -100); vertex(100, -(200 / 13) * 17, -100); vertex(100, -(200 / 13) * 17, -50 - (200 / 13) * 1); endShape(CLOSE); // frente der beginShape(); vertex(150, -(200 / 13) * 16, -50); vertex(150, -(200 / 13) * 16, -100); vertex(150, -(200 / 13) * 17, -100); vertex(150, -(200 / 13) * 17, -50); endShape(CLOSE); //triangle push() noStroke() beginShape(); vertex(150, -(200 / 13) * 17, -50 - (200 / 13) * 1) vertex(150, -(200 / 13) * 17, -50) vertex(150 - (200 / 13) * 1, -(200 / 13) * 17, -50 - (200 / 13) * 1) endShape(CLOSE); pop() } class Cuboid { constructor(x, w, y, h, z, d) { this.x = x this.w = w this.y = y this.h = h this.z = z this.d = d } draw() { beginShape(); vertex(this.x, this.y, this.z); vertex(this.x + this.w, this.y, this.z); vertex(this.x + this.w, this.y + this.h, this.z); vertex(this.x, this.y + this.h, this.z); endShape(CLOSE); beginShape(); vertex(this.x, this.y, this.z + this.d); vertex(this.x + this.w, this.y, this.z + this.d); vertex(this.x + this.w, this.y + this.h, this.z + this.d); vertex(this.x, this.y + this.h, this.z + this.d); endShape(CLOSE); beginShape(); vertex(this.x + this.w, this.y, this.z); vertex(this.x, this.y, this.z); vertex(this.x, this.y, this.z + this.d); vertex(this.x + this.w, this.y, this.z + this.d); endShape(CLOSE); beginShape(); vertex(this.x, this.y + this.h, this.z); vertex(this.x + this.w, this.y + this.h, this.z); vertex(this.x + this.w, this.y + this.h, this.z + this.d); vertex(this.x, this.y + this.h, this.z + this.d); endShape(CLOSE); beginShape(); vertex(this.x, this.y, this.z); vertex(this.x, this.y, this.z + this.d); vertex(this.x, this.y + this.h, this.z + this.d); vertex(this.x, this.y + this.h, this.z); endShape(CLOSE); beginShape(); vertex(this.x + this.w, this.y, this.z); vertex(this.x + this.w, this.y, this.z + this.d); vertex(this.x + this.w, this.y + this.h, this.z + this.d); vertex(this.x + this.w, this.y + this.h, this.z); endShape(CLOSE); } } Penrose Staircase Animation # Code ... let a; let i; function setup() { a = [false, false, false, false, false, false, false, false, false, false, false, false] i = 0 sliderx = createSlider(4, 7, 5.25, 0.01); sliderx.position(30, 30); slidery = createSlider(4, 7, 5.27, 0.01); slidery.position(30, 55); sliderz = createSlider(0, 10, 0, 0.01); sliderz.position(30, 80); createCanvas(700, 700, WEBGL); fill(237, 34, 93); // cuboid1 = new Cuboid(0, 50, 0, -(200 / 13) * 9, 0, 50); cuboid2 = new Cuboid(50, 50, 0, -(200 / 13) * 10, 0, 50); cuboid3 = new Cuboid(100, 50, 0, -(200 / 13) * 11, 0, 50); cuboid4 = new Cuboid(150, 50, 0, -(200 / 13) * 12, 0, 50); cuboid5 = new Cuboid(200, 50, 0, -(200 / 13) * 13, 0, 50); // cuboid6 = new Cuboid(0, 50, 0, -(200 / 13) * 8, 0, -50); cuboid7 = new Cuboid(0, 50, (200 / 13) * 5, -(200 / 13) * 12, -50, -50); cuboid8 = new Cuboid(0, 50, (200 / 13) * 5, -(200 / 13) * 11, -100, -50); // cuboid9 = new Cuboid(200, 50, 0, -(200 / 13) * 14, 0, -50); cuboid10 = new Cuboid(200, 50, 0, -(200 / 13) * 15, -50, -50); // cuboid11 = new Cuboid(150, 50, 0, -(200 / 13) * 16, -50, -50); //cuboid12 = new Cuboid(100, 50, -(200/13)*17, -(200/13)*1, -50, -50); setTimeout(verdadero, 1000) } function draw() { scale(0.5); background(200); rotateX(sliderx.value()); rotateY(slidery.value()); rotateZ(sliderz.value()); //console.log(sliderx.value()); //console.log(slidery.value()) //orbitControl() if (a[0] == true) { console.log(a) push() translate(50 / 2, -(200 / 13) * 10, 50 / 2) sphere(10) pop() } if (a[1] == true) { push() translate(50 + 50 / 2, -(200 / 13) * 11, 50 / 2) sphere(10) pop() } if (a[2] == true) { push() translate(100 + 50 / 2, -(200 / 13) * 12, 50 / 2) sphere(10) pop() } if (a[3] == true) { push() translate(150 + 50 / 2, -(200 / 13) * 13, 50 / 2) sphere(10) pop() } if (a[4] == true) { push() translate(200 + 50 / 2, -(200 / 13) * 14, 50 / 2) sphere(10) pop() } if (a[5] == true) { push() translate(200 + 50 / 2, -(200 / 13) * 15, 50 / 2 - 50) sphere(10) pop() } if (a[6] == true) { push() translate(200 + 50 / 2, -(200 / 13) * 15, 50 / 2 - 100) sphere(10) pop() } if (a[7] == true) { push() translate(150 + 50 / 2, -(200 / 13) * 16, 50 / 2 - 100) sphere(10) pop() } if (a[8] == true) { push() translate(100 + 50 / 2, -(200 / 13) * 17, 50 / 2 - 100) sphere(10) pop() } if (a[9] == true) { push() translate(50 / 2, -(200 / 13) * 7, 50 / 2 - 150) sphere(10) pop() } if (a[10] == true) { push() translate(50 / 2, -(200 / 13) * 8, 50 / 2 - 100) sphere(10) pop() } if (a[11] == true) { push() translate(50 / 2, -(200 / 13) * 9, 50 / 2 - 50) sphere(10) pop() } // first cuboid cuboid1.draw() cuboid2.draw() cuboid3.draw() cuboid4.draw() cuboid5.draw() cuboid6.draw() cuboid7.draw() cuboid8.draw() cuboid9.draw() cuboid10.draw() cuboid11.draw() // frente // push son para modificar el estilo y no afectar el resto de la plantilla push() noStroke() beginShape(); vertex(100, -(200 / 13) * 16, -50 - (200 / 13) * 2); vertex(150, -(200 / 13) * 16, -50 - (200 / 13) * 2); vertex(150, -(200 / 13) * 17, -50 - (200 / 13) * 1); vertex(100, -(200 / 13) * 17, -50 - (200 / 13) * 1); endShape(CLOSE); beginShape(); vertex(100, -(200 / 13) * 16, -100); vertex(150, -(200 / 13) * 16, -100); vertex(150, -(200 / 13) * 17, -100); vertex(100, -(200 / 13) * 17, -100); endShape(CLOSE); pop() //inferior beginShape(); vertex(150, -(200 / 13) * 16, -50 - (200 / 13) * 2); vertex(100, -(200 / 13) * 16, -50 - (200 / 13) * 2); vertex(100, -(200 / 13) * 16, -100); vertex(150, -(200 / 13) * 16, -100); endShape(CLOSE); //superior push() noStroke() beginShape(); vertex(100, -(200 / 13) * 17, -50 - (200 / 13) * 1); vertex(150, -(200 / 13) * 17, -50 - (200 / 13) * 1); vertex(150, -(200 / 13) * 17, -100); vertex(100, -(200 / 13) * 17, -100); endShape(CLOSE); pop() // frente izq beginShape(); vertex(100, -(200 / 13) * 16, -50 - (200 / 13) * 2); vertex(100, -(200 / 13) * 16, -100); vertex(100, -(200 / 13) * 17, -100); vertex(100, -(200 / 13) * 17, -50 - (200 / 13) * 1); endShape(CLOSE); // frente der beginShape(); vertex(150, -(200 / 13) * 16, -50); vertex(150, -(200 / 13) * 16, -100); vertex(150, -(200 / 13) * 17, -100); vertex(150, -(200 / 13) * 17, -50); endShape(CLOSE); //triangle push() noStroke() beginShape(); vertex(150, -(200 / 13) * 17, -50 - (200 / 13) * 1) vertex(150, -(200 / 13) * 17, -50) vertex(150 - (200 / 13) * 1, -(200 / 13) * 17, -50 - (200 / 13) * 1) endShape(CLOSE); pop() } function create() { ellipse(56, 46, 55, 55); setTimeout(create, 1000); } class Cuboid { constructor(x, w, y, h, z, d) { this.x = x this.w = w this.y = y this.h = h this.z = z this.d = d } draw() { beginShape(); vertex(this.x, this.y, this.z); vertex(this.x + this.w, this.y, this.z); vertex(this.x + this.w, this.y + this.h, this.z); vertex(this.x, this.y + this.h, this.z); endShape(CLOSE); beginShape(); vertex(this.x, this.y, this.z + this.d); vertex(this.x + this.w, this.y, this.z + this.d); vertex(this.x + this.w, this.y + this.h, this.z + this.d); vertex(this.x, this.y + this.h, this.z + this.d); endShape(CLOSE); beginShape(); vertex(this.x + this.w, this.y, this.z); vertex(this.x, this.y, this.z); vertex(this.x, this.y, this.z + this.d); vertex(this.x + this.w, this.y, this.z + this.d); endShape(CLOSE); beginShape(); vertex(this.x, this.y + this.h, this.z); vertex(this.x + this.w, this.y + this.h, this.z); vertex(this.x + this.w, this.y + this.h, this.z + this.d); vertex(this.x, this.y + this.h, this.z + this.d); endShape(CLOSE); beginShape(); vertex(this.x, this.y, this.z); vertex(this.x, this.y, this.z + this.d); vertex(this.x, this.y + this.h, this.z + this.d); vertex(this.x, this.y + this.h, this.z); endShape(CLOSE); beginShape(); vertex(this.x + this.w, this.y, this.z); vertex(this.x + this.w, this.y, this.z + this.d); vertex(this.x + this.w, this.y + this.h, this.z + this.d); vertex(this.x + this.w, this.y + this.h, this.z); endShape(CLOSE); } } function verdadero() { a[i] = true if (i != 0) { a[i - 1] = false } else { a[11] = false } if (i == 11) { i = 0 } else { i++ } setTimeout(verdadero, 1000) } Conclusión # En conclusión, las figuras imposibles, como el triángulo de Penrose, son aquellas que dibujadas pueden cumplir perfectamente dentro del espacio bidimensional, pero que no se pueden construir físicamente de ninguna manera, como lo son también el cuadrado, pentágono, hexágono y octógono de Penrose que tienen la misma lógica del triángulo.\nOtros poligonos de Penrose # Referencias # Tamir, A., \u0026amp; Ruiz Beviá, F. (2011). Geometría posible en 2D pero imposible en 3D. Cáceres González, J., Gegúndez Arias, M. E., Maestre Hachero, M., \u0026amp; Márquez Pérez, A. (2002). Algunas notas sobre mosaicos de Penrose. https://www.psicoactiva.com/blog/triangulo-de-penrose/ "},{"id":2,"href":"/visual_computing_page/docs/shortcodes/projections/","title":"Projections","section":"Shortcodes","content":" Proyecciones # Para estas proyecciones y su interpretacion se basa en The Math behind (most) 3D games - Perspective Projection, Esta difiere de la implementacion vista en clase debido a que varia el View Volume y el sistema de coordenadas, pero la explicacion nos da una buena introducción a lo que se busca con las proyecciones\nPara tener en cuenta esta usa el software vulkan q al igual que OpenGL tienen el objetivo de producir graficas en 3D\nNosotros en p5js usamos, WebGL is a web version on OpenGL, i.e a 3D engine. \u0026ldquo;It allows you to make 3D materials in the browser, using JavaScript. It is rendered using the GPU and thus is more performant than regular canvas, so it is also used for 2D games.\u0026rdquo; (Por lo que vemos que el sistema que usamos en clase es el mismo de OpenGL, asi que esto es simplemente demostrativo con otro caso)\nAhora bien en que difiere el View Volume de Vulkan con respecto al de OpenGL:\nEl de vulkan tiene las siguientes coordenadas que definen el cuboid:\n$$\\text{x from }(-1,1) $$\n$$\\text{y from }(-1,1)$$\n$$\\text{z from }(0,1)$$\nComo hemos dicho difiere del de OpenGL en el hecho de que el view volume es diferente, ya que en el caso de OpenGL es un cubo, en el que z va de -1 a 1, ademas de que el sistema de coordenadas en OpenGL es zurdo, mientras este es derecho\nProyeccion Ortogonal (Analogo, para otro View Volume y diferente sistema de coordenadas) # Una proyeccion ortogonal es una generalizacion del volumen de la vista que nos permite especificar las dimensiones y la ubicacion que queramos pero mantiene la forma general del volumen de la vista y mantiene fijas la direccion y la orientacion de la vista\nEn el caso de OpenGL:\nEN el caso de Vulkan: Ahora bien, continuando, lo que debemos hacer es:\nTener claro que el view volume tiene 6 planos que son right,left,top,bottom,far,near\nVolviendo al caso que estamos analizando:\nTranslate centre c, of near plane to origin: \\[c=\\left( \\frac{r\u0026#43;l}{2} , \\frac{b\u0026#43;t}{2} , n\\right)\\] Translation Matrix: \\[\\text{Translation Matrix =}\\begin{pmatrix} 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; -C_x\\\\ 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; -C_y\\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; -C_z\\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{pmatrix}\\] Reemplazando \\[ \\text{Translation Matrix=} \\begin{pmatrix} 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; -(r\u0026#43;l)/2\\\\ 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; -(b\u0026#43;t)/2\\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; -n\\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{pmatrix}\\] Scale Matrix to size of canonical Ahora bien en esta matriz para escalar es importante tener en cuenta que en los primeros 3 valores de la diagonal principal de la matriz, el numerador hace referencia a las dimensiones del view volume, en este caso (2,2,1), en el caso de OpenGL seria (2,2,2)\n\\[M_{ort}=\\begin{pmatrix} \\frac{2}{S_x} \u0026amp; 0\u0026amp; 0 \u0026amp; 0\\\\ 0 \u0026amp; \\frac{2}{S_y} \u0026amp; 0 \u0026amp; 0\\\\ 0 \u0026amp; 0 \u0026amp; \\frac{1}{S_z} \u0026amp; 0\\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{pmatrix}\\begin{pmatrix} 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; -(r\u0026#43;l)/2\\\\ 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; -(b\u0026#43;t)/2\\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; -n\\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{pmatrix}\\] Y el denominador van a ser las dimensiones del View Volume ortogonal\n\\[M_{ort}=\\begin{pmatrix} \\frac{2}{(r-l)} \u0026amp; 0 \u0026amp; 0 \u0026amp; 0\\\\ a \u0026amp; \\frac{2}{(b-t)} \u0026amp; 0 \u0026amp; 0\\\\ 0 \u0026amp; 0 \u0026amp; \\frac{1}{f-n} \u0026amp; 0\\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{pmatrix}\\begin{pmatrix} 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; -(r\u0026#43;l)/2\\\\ 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; -(b\u0026#43;t)/2\\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; -n\\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{pmatrix}=\\begin{pmatrix} \\frac{2}{(r\u0026#43;l)} \u0026amp; 0 \u0026amp; 0 \u0026amp; \\frac{-(r-l)}{(r-l)}\\\\ 0 \u0026amp; \\frac{2}{(b-t)} \u0026amp; 0 \u0026amp; \\frac{-(b\u0026#43;t)}{(b-t)}\\\\ 0 \u0026amp; 0 \u0026amp; \\frac{1}{(f-n)} \u0026amp; \\frac{-n}{(f-n)}\\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{pmatrix}\\] Al aplicar estas transformaciones a nuestros objetos, los objetos que se encuentran dentro de la region ocupada por el volumen de vista ortografica se escalaran y se moveran a la region cubierta por el volumen de vista canonica, y por lo tanto los !objetos se mostraran¡\nMatriz de perspectiva (OpenGL) # Pero el volumen de la vista ortografica no aplica la perspectiva, para ello necesitamos un volumen de visualizacion que no tenga forma de caja, sino una forma conocida como Square Frustrum\nLa idea del frustum cuadrado en la proyeccion es:\nEntonces lo que queremos es una matriz de perspetiva que transforme el tronco y cualquier objeto que contenga en el volumen de la vista Ortogonal\nPara ello es imporante la siguiente notación:\nYa entendido el concepto vamos a mostrar este ejemplo con la de OpenGL:\nEn OpenGL la matriz de perspectiva esta definida como: \\[\\left[\\begin{array}{cccc} { \\dfrac{2n}{ r-l } } \u0026amp; 0 \u0026amp; { \\dfrac{r \u0026#43; l} { r-l } } \u0026amp; 0 \\\\ 0 \u0026amp; { \\dfrac{2n}{ t-b } } \u0026amp; { \\dfrac{t \u0026#43; b}{ t-b } } \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; -{\\dfrac{f\u0026#43;n}{f-n}} \u0026amp; -{\\dfrac{2fn}{f-n}}\\\\ 0 \u0026amp; 0 \u0026amp; -1\u0026amp; 0\\\\ \\end{array}\\right]\\] Para empezar es importante recordar que las matrices en OpenGL, estan definidas usando Column Major Order\nCuando multiplicamos un punto homogéneo con esta matriz, la coordenada w del punto se multiplica por este elemento y el valor de w resulta ser la coordenada z del punto proyectado\nPrincipio de esto: Podemos usar el truco de triangulos similares. los triangulos A B C y D E F son similares. Por lo tanto podemos escribir:\nSi reemplazamos AB por n, el plano de recorte cercano, DE con Pz(la coordenada z de P) y EF con Py(la coordenada y de P) podemos reescribir esta ecuación como (ecuación 1): \\[{\\dfrac{n}{-P_z}} = {\\dfrac{BC}{P_y}} \\rightarrow BC = Ps_y = {\\dfrac{n * P_y}{-P_z}}.\\] Ahora bien aca podemos hacer el razonamiento de que (tenga en cuenta que debido a que la cámara está orientada a lo largo del eje z negativo,Pz es negativo:Pz\u0026lt; 0. Para mantener positiva la coordenada y del punto proyectado, ya que Py es positivo, tenemos que Pz). Si seguimos el mismo razonamiento encontramos la coordenada x del punto proyectado usando la siguiente ecuación: \\[Ps_x =\\dfrac{n * P_x}{-P_z}.\\] Ahora bien debemos relacional Psx y psy con la matriz de perspectiva.\nSi asumimos que Ps es visible, podemos escribir: \\[l \\leq Ps_x \\leq r.\\] donde l=left y r= right\nComencemos eliminando l de todos los términos y reescribiendo la ecuación anterior como: \\[0 \\leq Ps_x - l \\leq r - l.\\] Podemos normalizar dividiendo todos los perminos por r-l: \\[0 \\leq {\\dfrac{Ps_x - l}{r-l}} \\leq 1.\\] Multiplicamos los teminos por 2: \\[0 \\leq 2{\\dfrac{Ps_x - l}{r-l}} \\leq 2.\\] removiendo el -1 de todos los terminos: \\[-1 \\leq 2{\\dfrac{Ps_x - l}{r-l}} -1 \\leq 1.\\] Ahora remapeamos el termino central al rango [-1,1]:\n\\[-1 \\leq 2{ \\dfrac{Ps_x - l}{r-l} } - { \\dfrac{r-l}{r-l} } \\leq 1.\\] Teniendo: \\[-1 \\leq { \\dfrac{2Ps_x - 2l - r \u0026#43; l}{r-l} } \\leq 1.\\] Por lo tanto: \\[-1 \\leq { \\dfrac{2Ps_x - l - r}{r-l} } \\leq 1 \\rightarrow -1 \\leq { \\dfrac{2Ps_x}{r-l} } - { \\dfrac{r \u0026#43; l}{r - l} } \\leq 1.\\] esos dos terminos son similares a los 2 primeros de la primera fila de OpenGL perspective projection matrix, estamos cerca, por lo que reemplazamos Psx de la ecuacion previa con la ecuacion 2, teniendo: \\[-1 \\leq { \\dfrac{2 n P_x}{-P_z{(r-l)}} } - { \\dfrac{r \u0026#43; l}{r - l} } \\leq 1.\\] Podemos facilmente ponerlo en forma de matriz \\[ \\left[\\begin{array}{cccc} { \\dfrac{2n}{ r-l } } \u0026amp; 0 \u0026amp; { \\dfrac{r \u0026#43; l}{ r-l } } \u0026amp; 0 \\\\ ... \u0026amp; ... \u0026amp; ... \u0026amp; ... \\\\ ... \u0026amp; ... \u0026amp; ... \u0026amp; ... \\\\ 0 \u0026amp; 0 \u0026amp; -1\u0026amp; 0\\\\ \\end{array}\\right] \\] Recordando la notacion de multiplicacion por vectores columna de OpenGL: \\[\\left[\\begin{array}{cccc} { \\dfrac{2n}{ r-l } } \u0026amp; 0 \u0026amp; { \\dfrac{r \u0026#43; l}{ r-l } } \u0026amp; 0 \\\\ ... \u0026amp; ... \u0026amp; ... \u0026amp; ... \\\\ ... \u0026amp; ... \u0026amp; ... \u0026amp; ... \\\\ 0 \u0026amp; 0 \u0026amp; -1\u0026amp; 0\\\\ \\end{array}\\right] * \\left[ \\begin{array}{cccc}x \\\\ y \\\\ z \\\\ w\\end{array}\\right]\\] Computando Psx, usando las matrices dadas: \\[Ps_x = { \\dfrac{2n}{ r-l } } P_x \u0026#43; 0 * P_y \u0026#43; { \\dfrac{r \u0026#43; l}{ r-l } } * P_z \u0026#43; 0 * P_w.\\] Convirtiendo Ps de homogenea a coordenadas cartesianas: \\[Ps_x = \\dfrac { \\dfrac {2n} { r-l } P_x } { -P_z} \u0026#43; \\dfrac{ \\dfrac {r \u0026#43; l} { r-l } P_z } { -P_z} \\rightarrow \\dfrac {2n P_x} { -P_z (r-l) } - \\dfrac {r \u0026#43; l} { r-l }.\\] Reemplazando l y r con b y t: \\[-1 \\leq { \\dfrac{2 n P_y}{-P_z{(t-b)}} } - { \\dfrac{t \u0026#43; b}{t - b} } \\leq 1.\\] Podemos obtener este resultado con una multiplicación matricial puntual si reemplazamos los coeficientes segundo y tercero de la segunda fila de la matriz con el primer y segundo término de esta ecuación:\n\\[\\left[\\begin{array}{cccc} { \\dfrac{2n}{ r-l } } \u0026amp; 0 \u0026amp; { \\dfrac{r \u0026#43; l}{ r-l } } \u0026amp; 0 \\\\ 0 \u0026amp; { \\dfrac{2n}{ t-b } } \u0026amp; { \\dfrac{t \u0026#43; b}{ t-b } } \u0026amp; 0 \\\\ ... \u0026amp; ... \u0026amp; ... \u0026amp; ... \\\\ 0 \u0026amp; 0 \u0026amp; -1\u0026amp; 0\\\\ \\end{array}\\right]\\] Computando Psy usando las matrices dadas:\n\\[Ps_y = 0 * P_x \u0026#43; { \\dfrac{2n}{ (t-b) } } * P_y \u0026#43; { \\dfrac{t \u0026#43; b}{ t-b } } * P_z \u0026#43; 0 * P_w\\] Y despues de la division por -Pz: \\[Ps_y = \\dfrac { \\dfrac {2n} {t - b} P_y } { -P_z} \u0026#43; \\dfrac{ \\dfrac {t \u0026#43; b} {t - b} P_z } { -P_z} \\rightarrow \\dfrac {2n P_y} { -P_z (t - b) } - \\dfrac {t \u0026#43; b} {t - b}\\] La matriz vuelve a funcionar, y Por lo tanto, los coeficientes primero y segundo de la tercera fila de la matriz, que se multiplicarían por las coordenadas P x e y, son necesariamente cero (en verde). Nos quedan dos coeficientes A y B en la matriz que son desconocidos (en rojo). \\[\\left[\\begin{array}{cccc} { \\dfrac{2n}{ r-l } } \u0026amp; 0 \u0026amp; { \\dfrac{r \u0026#43; l}{ r-l } } \u0026amp; 0 \\\\ 0 \u0026amp; { \\dfrac{2n}{ t-b } } \u0026amp; { \\dfrac{t \u0026#43; b}{ t-b } } \u0026amp; 0 \\\\ \\color{green}0 \u0026amp; \\color{green}0 \u0026amp; \\color{red}A \u0026amp; \\color{red}B \\\\ 0 \u0026amp; 0 \u0026amp; -1\u0026amp; 0\\\\ \\end{array}\\right]\\] Si escribimos las ecuacion para computar Psz (recordando que Psz se divide tambien por Psw, cuando el punto es convertido de homogenea a cooredeandas cartesianas, y que Pw=1): \\[Ps_z = \\dfrac{0 * P_x \u0026#43; 0 * P_y \u0026#43; A * P_z \u0026#43; B * P_w}{Ps_w = -P_z} \\rightarrow \\dfrac{A P_z \u0026#43; B}{Ps_w = -P_z}.\\] Necesitamos encontrar el valor de A y B. Con suerte sabemos que cuando Pz encuentra en el plano de recorte cercano,Psz ser reasignado a -1 y Pz encuentra en el plano de recorte lejano,Psz necesita ser reasignado a 1. Por lo tanto, necesitamos reemplazar Psz por n y f la ecuación para obtener dos nuevas ecuaciones (tenga en cuenta que la coordenada z de todos los puntos proyectados en el plano de la imagen son negativas pero n y F son positivos por lo tanto usaremos -n y -f cambio): \\[\\left\\{ \\begin{array}{ll} \\dfrac{(P_z=-n)A \u0026#43; B}{(-P_z=-(-n)=n)} = -1 \u0026amp;\\text{ when } P_z = n\\\\ \\dfrac{(P_z=-f)A \u0026#43; B}{(P_z=-(-f)=f)} = 1 \u0026amp; \\text{ when } P_z = f \\end{array} \\right. \\\\ \\rightarrow \\left\\{ \\begin{array}{ll} {-nA \u0026#43; B} = -n \u0026amp; (1)\\\\ {-fA \u0026#43; B} = f \u0026amp; (2) \\end{array} \\right.\\] Resolviendo B en la ecuacion 1: \\[B = -n \u0026#43; An.\\] Sustituyendo B en la ecuacion 2, con est ecuacion: \\[-fA - n \u0026#43; An = f. \\] Luego resolviendo A: \\[-fA \u0026#43; An = f \u0026#43; n \\rightarrow -(f - n)A = f \u0026#43; n \\rightarrow A = -\\dfrac{f \u0026#43; n}{f - n}. \\] Ya que tenemos la solucion para A, es facil encontrar B, solo necesitamos reemplazar A en la ecuacion 1 para encontrar B: \\[B = -n \u0026#43; An= -n -\\dfrac{f \u0026#43; n}{f - n} n = \\\\-(1\u0026#43;\\dfrac{f \u0026#43; n}{f - n}) n = - \\dfrac{{(f -n \u0026#43; f \u0026#43; n)}n}{f - n}=-\\dfrac { 2fn }{f -n}\\] Hallado A y B, finalmente tenemos que \\[\\left[\\begin{array}{cccc} { \\dfrac{2n}{ r-l } } \u0026amp; 0 \u0026amp; { \\dfrac{r \u0026#43; l}{ r-l } } \u0026amp; 0 \\\\ 0 \u0026amp; { \\dfrac{2n}{ t-b } } \u0026amp; { \\dfrac{t \u0026#43; b}{ t-b } } \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; -{\\dfrac{f\u0026#43;n}{f-n}} \u0026amp; -{\\dfrac{2fn}{f-n}}\\\\ 0 \u0026amp; 0 \u0026amp; -1\u0026amp; 0\\\\ \\end{array}\\right]\\] "},{"id":3,"href":"/visual_computing_page/docs/shortcodes/rasterization/","title":"Rasterization","section":"Shortcodes","content":" Rasterization # Dentro del ámbito se han estudiado varios algoritmos de representación y técnicas para la obtención de imágenes, ya que analizar una partícula de luz en un espacio considerablemente grande no es práctico ni eficiente, y por eso se debe realizar un muestreo de manera inteligente para producir una imagen.\nUna de las técnicas utilizadas para lograr tal eficiencia es la rasterización (raster con significado en cine y televisión, refiriéndose a un tubo catódico que permite visualizar imágenes mediante un haz de rayos catódicos) que toma la imagen descrita por gráficos vectoriales (formas geométricas dependientes) y la convierte en un conjunto de pixeles que a su vez se utilizan para salidas digitales. Se suele utilizar para dos momentos en específico; cuando se trabaja con imágenes de gran complejidad o cuando se van a aplicar filtros sobre la imagen resultante.\nUna representación común en los modelos digitales 3D es el poligonal, pero antes de que sean rasterizados, esos polígonos deben dividirse en triángulos, de manera que primero se debe definir la rasterización de un triángulo. Se requiere primeramente que la rasterización de dos triángulos adyacentes, que son aquellos que comparten una arista, no dejen espacios vacíos entre los triángulos (pixeles no rasterizados) para que el área de los triángulos adyacentes y superficie rasterizada esté llena por completo, sin necesidad de superponer los triángulos.\nEsto lleva a establecer reglas de rasterización para garantizar las condiciones anteriores. Un conjunto de tales reglas se denomina regla superior izquierda, que establece que un píxel se rasteriza si y sólo si su centro se encuentra completamente dentro del triángulo. O su centro se encuentra exactamente en el borde del triángulo (o múltiples bordes en el caso de las esquinas) que es (o, en el caso de las esquinas, todos son) el borde superior o el izquierdo.\nRenderizado de software (Software Rendering) # ¿Qué es? Proceso que utiliza un software específico (comunes en diferentes áreas; cine, videojuegos, arquitectura, efectos en películas, simulaciones, entre otros) para tener como resultado una imagen a partir de un modelo.\nEste tipo de renderizado puede dividirse en dos tipos; uno en tiempo real y el otro previamente renderizado, el primero utilizado por lo general para videojuegos en donde se requiere que se vaya actualizando a medida que se vaya jugando, esperando respuestas en milisegundos, mientras que un renderizado fuera de línea puede verse aplicada en imágenes, películas en que se requieren escenas realistas y que usualmente se demoran en dar el resultado final, por ejemplo en películas animadas en donde conjuga una serie de elementos como la apariencia final de los elementos, texturas, sombras, enfoque de movimiento, efectos, y en general todo el proceso de animación. En la CPU suele renderizarse íntegramente los modelos ya que tiene la ventaja de que no está restringida a la capacidad de los gráficos, que de por sí son limitados, aunque cabe resaltar que se necesitan más semiconductores para alcanzar un buen rendimiento.\nProcesador de software ejecutándose en un dispositivo sin GPU.\nEstado del arte # Aplicaciones\nDentro de las aplicaciones con renderizado en tiempo real se pueden hallar sobre todo videojuegos, uno de los primeros fue Descent que permitía modelos en 3D todo con base en lo que repasamos de rasterización triangular, los cuales convertía en mapas de bits, como otros tantos juegos de la época que utilizaron esta misma representación y que por ende se aumentaron las ventas en ciertos componentes de cómputo (tarjetas gráficas) y también el aprovechamiento del uso de API’s como OpenGL. Luego en juegos arcade y en los mismos mercados de consolas de videojuegos se orientó modelos 3D mucho más avanzados y con las llegada de 16 bits en consolas se aceleraron muchos procesos con el uso de cartuchos RISC. A partir de esto, ha crecido constantemente el rendimiento de cómputo para poder renderizar sobre hardware de gráficos y que nuevas tecnologías de renderizado de software sigan promoviendo nuevos procesos como la compilación dinámica, que optimiza y mejora el rendimiento. Con respecto al renderizado fuera de línea, podemos encontrar sobre todo ejemplos en la industria cinematográfica para la creación de escenas realistas y personajes generados por computadora. Pixar sentó un precedente con la película Toy Story, también con Buscando a Nemo, y debido a todos los detalles que confluyen el renderizado sin conexión brinda la posibilidad de manejar la diversidad de efectos como se maneja, apoyándose en la flexibilidad permite sombreadores de longitud, y alto realismo como el trazado de rayos e iluminación global, dentro de las producciones de objetos con movimiento que requieren procesadores de propósito general de la más alta calidad. Se cree además que el crecimiento va a ser tan inmensurable que CPU y GPU convergerán de alguna manera u otra haciendo que la línea entre software y hardware desaparezca.\nAliasing and Anti alising in Computer Graphics # What is Aliasing # En gráficos por computadora, el proceso por el cual las curvas suaves y otras líneas se vuelven irregulares (jagged) debido a que la resolución del dispositivo de gráficos del archivo no es lo suficientemente alta para representar una curva suave.\nEn los algoritmos de dibujo de líneas, hemos visto que todas las ubicaciones rasterizadas no coinciden con la línea verdadera y tenemos que seleccionar las ubicaciones de raster óptimas para representar una línea recta. Este problema es grave en pantallas de baja resolución. En tales pantallas, la línea aparece como un escalón.\nAnti aliasing and methods # Anti aliasing es una tecnica usada en computación grafica para remover el efecto de Aliasing\nLos metodos principales de anti-aliasing:\nSSAA (Super Sample Anti Aliasing): SSAA es una manera muy efectiva de combatir el Aliasing, y fue la primera que estuvo disponible. No obstante ya no se utiliza demasiado porque tiene un alto impacto en el rendimiento, ya que lo que hace es obligar a la GPU a renderizar los juegos a mayor resolución de la que se muestra y luego generar una imagen a la resolución de salida del monitor MSAA (Multi Sampling Anti Aliasing): MSAA es uno de los modos más comunes, pero tan solo es capaz de suavizar polígonos, aunque a cambio tiene un menor impacto en el rendimiento. Su forma de combatir el Aliasing se hace mediante el renderizado de más frames de la cuenta, sacando muestras y combinando ambos. Hay diferentes niveles de intensidad, por lo que podréis ver que existen opciones como 2xMSAA, 4xMSAA y 8xMSAA. CSAA (Coverage Sampling Anti Aliasing) y EQAA (Enhanced Quality Anti Aliasing): CSAA fue desarrollado por NVIDIA, mientras que EQAA es su equivalente para gráficas AMD. Ambos funcionan igual que MSAA pero optimizados para sus respectivas gráficas, por lo que tienen un menor impacto en el rendimiento. FXAA (Fast Approximate Anti Aliasing): este modo se considera el de menor grado, ya que es el que menos se nota su efecto y el que menor impacto tiene en el rendimiento, por lo que es el modo recomendado para PCs de gama baja o que vayan «justos» en los juegos. No hace mal su trabajo a la hora de mitigar los bordes de sierra, pero tiene un defecto y es que a veces produce que las imágenes se vean algo borrosas. TXAA (Temporal Anti Aliasing): TXAA utiliza algo más de recursos de la GPU que FXAA, pero combina diferentes técnicas de las anteriores para conseguir unos bordes más suaves y mitigar más el Aliasing. No obstante, tampoco es perfecto y también causa a veces que las imágenes se vean algo borrosas. Vamos a ahondar en lo que es el segundo metodo:\nPost filtering (Multisamppling) # Vamos a ver a traves de un ejercicio, la nocion basica bajo la que funciona este tipo de antialiasing\nCódigo # Code ... let upScale = 0.4; let quadrille; let subquadrille; let DIVIDE_QUADRILLE=15 let DIVIDE_SUBQUADRILLE=4 let img function preload() { img = loadImage(\u0026#34;/visual_computing_page/sketches/happy.jpg\u0026#34;) } function setup() { createCanvas((img.width * upScale) , img.height * upScale); loadImage(\u0026#34;/visual_computing_page/sketches/happy.jpg\u0026#34;, loadedImage =\u0026gt; { // when the image is fully loaded img = loadedImage; // make pixels available img.loadPixels(); background(\u0026#39;#a8b8f8\u0026#39;); // blurred version //image(img, 0, 0, img.width * upScale, img.height * upScale); }) quadrille = createQuadrille(DIVIDE_QUADRILLE, DIVIDE_QUADRILLE); subquadrille = createQuadrille(DIVIDE_SUBQUADRILLE * DIVIDE_QUADRILLE, DIVIDE_SUBQUADRILLE * DIVIDE_QUADRILLE); } function draw() { background(img); drawQuadrille(subquadrille, { cellLength: ((img.width * upScale) / DIVIDE_QUADRILLE) / DIVIDE_SUBQUADRILLE, outline: \u0026#39;blue\u0026#39;, board: true }); drawQuadrille(quadrille, { cellLength: ((img.width * upScale) / DIVIDE_QUADRILLE), outline: \u0026#39;green\u0026#39;, board: true }); //getAliasedGraphics(img) } function keyPressed() { if (key === \u0026#39;c\u0026#39;) { quadrille.clear(); } if (key === \u0026#39;t\u0026#39;) { getAliasedGraphics(img) } } function getAliasedGraphics(img) { let imageWidth = img.width; //console.log(imageWidth) //console.log(img.height) let pixels = img.pixels; let arr = Array.from(pixels) //console.log(typeof(pixels)) //console.log(arr) let numBytes = pixels.length; //console.log(numBytes) //console.log(img.pixels.BYTES_PER_ELEMENT) // remember in p5 pixels are R,G,B,A bytes, so skip every 4 bytes for 1 pixel // pixelIndex in this case is counting 1 pixel at time // division por 4, (por los colores) var perChunk = 4 arr = arr.reduce((resultArray, item, index) =\u0026gt; { const chunkIndex = Math.floor(index/perChunk) if(!resultArray[chunkIndex]) { resultArray[chunkIndex] = [] // start a new chunk } resultArray[chunkIndex].push(item) return resultArray }, []) console.log(arr) const newArr = []; // Aca se crea la matriz original de pixeles cada uno con un arreglo de 4 representado los colores while(arr.length) newArr.push(arr.splice(0,img.width)); //console.log(newArr) // Ahora vamos a dividir la matriz tomando muestras de cada una de subcuadrillas en la esquina superior izquierda list = [] let c =0 for (let i = 0; i \u0026lt; img.height; i += Math.floor((img.width/(DIVIDE_QUADRILLE*DIVIDE_SUBQUADRILLE)))) { for(let j = 0; j \u0026lt; img.width; j += Math.floor((img.width/(DIVIDE_QUADRILLE*DIVIDE_SUBQUADRILLE)))){ let r = newArr[i][j][0]; let g = newArr[i][j][1]; let b = newArr[i][j][2]; let a = newArr[i][j][3]; list.push([r, g, b, a]) //console.log(r,g,b,a,i,j) } } console.log(list.length) // debido a que a priori sabemos que se tienen 4 de estas subcuadriculas por fila para completar la cuadrilla, lsa dividimos var perChunk = DIVIDE_SUBQUADRILLE var result = list.reduce((resultArray, item, index) =\u0026gt; { const chunkIndex = Math.floor(index/perChunk) if(!resultArray[chunkIndex]) { resultArray[chunkIndex] = [] // start a new chunk } resultArray[chunkIndex].push(item) return resultArray }, []) console.log(result) // Ahora habiendo completado cada una de las filas de subcuadrillas para completar una cuadrilla, creamos una matriz con respecto a el ancho de la imagen // Aca se crea la matriz dividePixels = [] while(result.length) dividePixels.push(result.splice(0,DIVIDE_QUADRILLE)); console.log(dividePixels.length) let join_square =[] let temp = [] for(let i =0 ; i\u0026lt; DIVIDE_QUADRILLE; i++){ for(let j =0 ; j\u0026lt;dividePixels.length ; j++){ console.log(j,i) temp.push(dividePixels[j][i]) if(j%DIVIDE_SUBQUADRILLE==DIVIDE_SUBQUADRILLE-1){ // completemos cada una de las subcuadrillas dentro de una cuadrilla para luego sacar el promedio join_square.push(temp) temp=[] } } } divide_join=[] while(join_square.length) divide_join.push(join_square.splice(0,DIVIDE_QUADRILLE)); for(let i =0 ; i\u0026lt; DIVIDE_QUADRILLE ; i++){ for(let j =0 ; j\u0026lt; DIVIDE_QUADRILLE ; j++){ let r=0 let g=0 let b=0 let a=0 for(let k =0 ; k\u0026lt;DIVIDE_SUBQUADRILLE ; k++){ for(let l=0 ; l\u0026lt;DIVIDE_SUBQUADRILLE ; l++){ r += divide_join[i][j][k][l][0] g += divide_join[i][j][k][l][1] b +=divide_join[i][j][k][l][2] a += divide_join[i][j][k][l][3] } } r = r/(DIVIDE_SUBQUADRILLE*DIVIDE_SUBQUADRILLE); g = g/(DIVIDE_SUBQUADRILLE*DIVIDE_SUBQUADRILLE); b = b/(DIVIDE_SUBQUADRILLE*DIVIDE_SUBQUADRILLE); a = a/(DIVIDE_SUBQUADRILLE*DIVIDE_SUBQUADRILLE); quadrille.fill(j, i, color(r,g,b,a)); } } } Imagen Original a analizar # Imagen Original a escala 0.4, division de 15, subdivision de 4 # Imagen Original a escala 0.4, division de 5, subdivision de 5 # Imagen Original a escala 0.4, division de 40, subdivision de 10 # Fuentes # [1] https://www.youtube.com/watch?v=Ahg6tWA1Qzo\n[2] https://hardzone.es/reportajes/que-es/anti-aliasing-juegos/\n[3] https://en-m-wikipedia-org.translate.goog/wiki/Software_rendering?_x_tr_sl=en\u0026_x_tr_tl=es\u0026_x_tr_hl=es\u0026_x_tr_pto=sc\n"},{"id":4,"href":"/visual_computing_page/docs/shortcodes/scene_tree/","title":"Scene Tree","section":"Shortcodes","content":" Scene Trees # This demo illustrates a 3D painting application that makes use of screen to world transformations, similar to those employed in ray-casting.\nWorkshop\nImplement a 3d brush based on the code above. Don’t forget to check its comments. The p5.treegl library may be used.\nPara esta parte del trabajo se implmento la libreria https://ml5js.org/ en especifico la parte de deteccion de la mano (handpose), siendo que el trazado de puntos ya no se implementa con el mouse, sino por el movimiento del dedo indice de la mano, ademas se implemento que con el gesto de unir la punta del dedo indice y del dedo pulgar cambiar a un color azul el trazado, esto se hiso apoyado en la distancia de Euler.\n"},{"id":5,"href":"/visual_computing_page/docs/shortcodes/shaders/","title":"Shaders","section":"Shortcodes","content":" Shaders # Ejemplo de shader en figura geometrica, simplemente se cambio el objeto y la imagen, Creación Original\nQue es y Funcionamiento: # Se entiende como shader a un script especifico con lenguaje GLSL o HLSL en la que las instrucciones del script se comunican y se ejecutan directamente en la placa de video sin pasar por el procesador . Esta ejecución directo en la placa de video es la que nos permite ahorrarnos el problema de la memoria y el procesador de la computadora a la hora de procesar esa información grafica (asi es como existen intros 4kb alucinantes y super realistas que pesan tan poco). Esto también conlleva una limitación que es que los scripts de shaders solo pueden recibir información de variables externas (uniforms), pero esa información solo puede salir en formato de textura, es decir, es imposible utilizar un shader para asignar el valor de un float,bool,int o cualquier tipo de dato primitivo y que eso salga del alcance del shader. Las salidas de los shaders siempre son en texturas(información de imagen). Tomado de mmtt.com.arg\nTipos de shaders # Fragment shader : este tipo de shader fue creado originalmente para manejar el color de las texturas que se aplican a los objetos 3D, pero dada su dinamismo a la hora de procesar los pixeles se inventaron tecnicas como RayMarching que permiten simular luces, y escenarios 3D super realistas solamente utilizando codigo.\nVertex Shader : Los vertex shaders son utilizados para procesar información de los vertices de una figura. Es decir, lo puntos que conectan con otros puntos que hace que se genere un triangulo, y mediante muchos de esos triangulos es como se componen los modelos 3D. Los vertex shader permiten modificar la posicion de estos puntos de vertices.\nCompute shader : Los compute shaders son shaders utilizados para computar una gran cantidad de datos utilizando la tecnologia propia de los shaders. Esto sirve por ejemplo para hacer sistemas de particulas con millones y millones de particulas. A esta tecnica se la conoce como GPU INSTANCING.\nTomado de mmtt.com.arg\nEstructura general con la que funcionan el vertex y fragment shader:\nCODE - Two colors interpolated with patterns in p5js # Sketch Code ... let uvShader; let parDef = { time: 1, Save: function () { save(\u0026#39;frag_texture.png\u0026#39;); }, }; function preload() { // Define geometry directly in clip space (i.e., matrices: Tree.NONE). // Interpolate only texture coordinates (i.e., varyings: Tree.texcoords2). // see: https://github.com/VisualComputing/p5.treegl#handling uvShader = readShader(\u0026#39;/visual_computing_page/sketches/shader_basic_frag.frag\u0026#39;, { matrices: Tree.NONE, varyings: Tree.texcoords2 }); } function setup() { let gui = new dat.GUI(); gui.add(parDef, \u0026#39;time\u0026#39; , 0, 2, 0.25 ).listen(); gui.add(parDef, \u0026#39;Save\u0026#39;).name(\u0026#34;Save png\u0026#34;); // shaders require WEBGL mode to work createCanvas(400, 400, WEBGL); color1= createColorPicker(color(0,255,255)); //console.log(color1.color().levels) color1.position(0,0) color1_n = color1.color().levels.map(function(item) { return item/255 }); print(color1_n) color2= createColorPicker(color(0,255,0)); color2.position(0,20) noStroke(); resetShader(); shader(uvShader); } function draw() { background(0); // see: https://p5js.org/reference/#/p5/shader // https://p5js.org/reference/#/p5/textureMode // best and simplest is to just always used NORMAL uvShader.setUniform(\u0026#39;resolution\u0026#39;, [width, height]); uvShader.setUniform(\u0026#39;mouse\u0026#39;, map(mouseX, 0, width, 0, 7)); uvShader.setUniform(\u0026#39;time\u0026#39;, frameCount * 0.01*parDef.time); uvShader.setUniform(\u0026#39;c1\u0026#39;, normalizecolor(color1)); uvShader.setUniform(\u0026#39;c2\u0026#39;, normalizecolor(color2)); textureMode(NORMAL); // clip-space quad (i.e., both x and y vertex coordinates ∈ [-1..1]) // https://p5js.org/reference/#/p5/quad // It\u0026#39;s worth noting (not mentioned in the api docs) that the quad // command also adds the texture coordinates to each of its vertices. quad(-1,-1,1,-1,1,1,-1,1); } function normalizecolor(color){ return color.color().levels.map(function(item) { return item/255 }); } Fragment Shader ... precision highp float; uniform float time; uniform vec2 resolution; uniform vec2 mouse; uniform vec4 c1; uniform vec4 c2; #define pi 3.1416 float def(vec2 uv, float f){ const int cant =20; float e =0.; for(int i=0 ; i\u0026lt;cant ; i++){ //definimos un punto que va a estar en el centro vec2 p = vec2(0.5,float(i)/float(cant))-uv; // radio float rad = length(p); // angulo float angulo = atan(p.x,p.y); e += sin(rad*20.+f+time); e+=sin(e*pi)*0.2; } e/=float(cant)/4.; return abs(e); } void main(void){ //Variable contiene el eje de coordenadas vec2 uv = gl_FragCoord.xy / resolution; // Variable de forma float e = def(uv,0.); float e2 =def(uv,pi/6.); float e3 = abs(e2); // Variable final vec4 fin = vec4(e)*c1*c1.a+vec4(e2)*c2*c2.a; // Variable final donde toma el color el shader gl_FragColor = fin; } CODE - Three Colors interpolated with patterns in p5js # Sketch Code ... let uvShader; let parDef = { time: 1, Save: function () { save(\u0026#39;frag_texture.png\u0026#39;); }, }; function preload() { // Define geometry directly in clip space (i.e., matrices: Tree.NONE). // Interpolate only texture coordinates (i.e., varyings: Tree.texcoords2). // see: https://github.com/VisualComputing/p5.treegl#handling uvShader = readShader(\u0026#39;/visual_computing_page/sketches/three_interpolated.frag\u0026#39;, { matrices: Tree.NONE, varyings: Tree.texcoords2 }); } function setup() { let gui = new dat.GUI(); gui.add(parDef, \u0026#39;time\u0026#39; , 0, 2, 0.25 ).listen(); gui.add(parDef, \u0026#39;Save\u0026#39;).name(\u0026#34;Save png\u0026#34;); // shaders require WEBGL mode to work createCanvas(400, 400, WEBGL); color1= createColorPicker(color(0,255,255)); //console.log(color1.color().levels) color1.position(0,0) color1_n = color1.color().levels.map(function(item) { return item/255 }); //print(color1_n) color2= createColorPicker(color(0,255,0)); color2.position(0,20) color3= createColorPicker(color(255,255,0)); color3.position(0,40) noStroke(); resetShader(); shader(uvShader); } function draw() { background(0); // see: https://p5js.org/reference/#/p5/shader // https://p5js.org/reference/#/p5/textureMode // best and simplest is to just always used NORMAL uvShader.setUniform(\u0026#39;resolution\u0026#39;, [width, height]); uvShader.setUniform(\u0026#39;mouse\u0026#39;, map(mouseX, 0, width, 0, 7)); uvShader.setUniform(\u0026#39;time\u0026#39;, frameCount * 0.01*parDef.time); uvShader.setUniform(\u0026#39;c1\u0026#39;, normalizecolor(color1)); uvShader.setUniform(\u0026#39;c2\u0026#39;, normalizecolor(color2)); uvShader.setUniform(\u0026#39;c3\u0026#39;, normalizecolor(color3)); textureMode(NORMAL); // clip-space quad (i.e., both x and y vertex coordinates ∈ [-1..1]) // https://p5js.org/reference/#/p5/quad // It\u0026#39;s worth noting (not mentioned in the api docs) that the quad // command also adds the texture coordinates to each of its vertices. quad(-1,-1,1,-1,1,1,-1,1); } function normalizecolor(color){ return color.color().levels.map(function(item) { return item/255 }); } Fragment Shader ... #ifdef GL_ES precision mediump float; #endif uniform float time; uniform vec2 resolution; uniform vec2 mouse; uniform vec4 c1; uniform vec4 c2; uniform vec4 c3; #define pi 3.1416 float def(vec2 uv, float f){ const int cant =30; float e =0.; for(int i=0 ; i\u0026lt;cant ; i++){ //definimos un punto que va a estar en el centro vec2 p = vec2(float(i),float(i)/float(cant))-uv; // radio float rad = length(p); // angulo float angulo = atan(p.x,p.y); e += sin(rad*20.+f+time); e+=sin(e*pi)*0.2; } e/=float(cant)/4.; return abs(e); } void main(void){ //Variable contiene el eje de coordenadas vec2 uv = gl_FragCoord.xy / resolution; // Variable de forma float e = def(uv,0.); float e2 =def(uv,pi/6.); float e3 = abs(e2+e); // Variable final vec4 fin = vec4(e)*c1*c1.a+vec4(e2)*c2*c2.a+vec4(e3)*c3*c3.a; // Variable final donde toma el color el shader gl_FragColor = fin; } CODE - Texture sampling # Sketch Code ... let lumaShader; let img; let grey_scale; function preload() { lumaShader = readShader(\u0026#39;/visual_computing_page/sketches/texture_sampling.frag\u0026#39;, { varyings: Tree.texcoords2 }); // image source: https://en.wikipedia.org/wiki/HSL_and_HSV#/media/File:Fire_breathing_2_Luc_Viatour.jpg img = loadImage(\u0026#39;/visual_computing_page/sketches/fire_breathing.jpg\u0026#39;); } function setup() { createCanvas(700, 500, WEBGL); noStroke(); textureMode(NORMAL); shader(lumaShader); sel = createSelect(); sel.position(10, 10); sel.option(\u0026#39;none\u0026#39;); sel.option(\u0026#39;luma\u0026#39;); sel.option(\u0026#39;hsl\u0026#39;); sel.option(\u0026#39;hsv\u0026#39;); sel.option(\u0026#39;diffuse\u0026#39;); sel.option(\u0026#39;average\u0026#39;); sel.selected(\u0026#39;none\u0026#39;); lumaShader.setUniform(\u0026#39;texture\u0026#39;, img); sel.changed(mySelectEvent) } function draw() { background(0); quad(-width / 2, -height / 2, width / 2, -height / 2, width / 2, height / 2, -width / 2, height / 2); } function mySelectEvent(){ if(sel.value() == \u0026#39;luma\u0026#39;){ lumaShader.setUniform(\u0026#39;grey_scale\u0026#39;, 1) }else if(sel.value() == \u0026#39;hsl\u0026#39;){ lumaShader.setUniform(\u0026#39;grey_scale\u0026#39;, 2) }else if(sel.value()==\u0026#39;hsv\u0026#39;){ lumaShader.setUniform(\u0026#39;grey_scale\u0026#39;, 3) }else if(sel.value()==\u0026#39;diffuse\u0026#39;){ lumaShader.setUniform(\u0026#39;grey_scale\u0026#39;, 4) }else if(sel.value()==\u0026#39;average\u0026#39;){ lumaShader.setUniform(\u0026#39;grey_scale\u0026#39;, 5) } else{ lumaShader.setUniform(\u0026#39;grey_scale\u0026#39;, 0) } } Fragment Shader ... precision mediump float; // uniforms are defined and sent by the sketch uniform int grey_scale; uniform sampler2D texture; // interpolated texcoord (same name and type as in vertex shader) varying vec2 texcoords2; // returns luma of given texel float luma(vec3 texel) { return 0.299 * texel.r + 0.587 * texel.g + 0.114 * texel.b; } // returns hsl of given texel float hsl(vec3 texel) { return max(max(texel.r, texel.g), texel.b)/2.0 + min(min(texel.r, texel.g), texel.b)/2.0; } // returns hsv of given texel float hsv(vec3 texel) { return max(max(texel.r, texel.g), texel.b); } // returns difuse of given texel float color_difuse(vec3 texel, float gray, float res, float scl) { float threshR = (fract(floor(texel.r*res)/scl)*scl) * gray ; float threshG = (fract(floor(texel.g*res)/scl)*scl) * gray ; float threshB = (fract(floor(texel.b*res)/scl)*scl) * gray ; return (threshR+threshG,threshB)/3.0; } // returns average of given texel float average(vec3 texel){ return (texel.r + texel.g + texel.b)/3.0; } void main() { // texture2D(texture, texcoords2) samples texture at texcoords2 // and returns the normalized texel color vec4 texel = texture2D(texture, texcoords2); float gray = average(texel.rgb); float res = 20.0; float scl = res/(10.0); if(grey_scale==1) gl_FragColor = vec4((vec3(luma(texel.rgb))), 1.0); else if(grey_scale==2) gl_FragColor = vec4((vec3(hsl(texel.rgb))), 1.0); else if(grey_scale==3) gl_FragColor = vec4((vec3(hsv(texel.rgb))), 1.0); else if(grey_scale==4) gl_FragColor = vec4((vec3(color_difuse(texel.rgb,gray,res,scl))), 1.0); else if(grey_scale==5) gl_FragColor = vec4((vec3(gray)), 1.0); else gl_FragColor = texel; } Procedural Texturing # El campo de la informática visual, donde se utilizan computadoras para generar imágenes visuales y espaciales del mundo real se conoce como computación gráfica.\nEl texturizado en computación gráfica es una técnica muy común utilizada para añadir detalles a la superficie de un objeto. Con un objeto lo que se puede hacer es renderizarlo como un objeto difuso, por ejemplo, utilizando un color sólido para todo el objeto. Si se requiere que el objeto no tenga solo un color sólido, la solución alternativa es dividir el objeto en partes más pequeñas y dar un valor o color único a cada parte del objeto. Romper el objeto para seguir la forma de los detalles de la textura que se quiere aplicar a la superficie de un objeto lleva mucho tiempo y, aunque funciona si el patrón aplicado está hecho sólo de colores sólidos, no funciona si se desea aplicar algunos gradientes de colores en la superficie del objeto.\nEn computación gráfica el patrón aplicado a la superficie de un objeto puede ser una imagen, pero también puede generarse mediante algún tipo de ecuación matemática. Está segunda técnica se denomina texturizado procedimental. La ventaja de este enfoque es el bajo costo de almacenamiento, la resolución ilimitada de las texturas y la facilidad de mapeo de las mismas. Este tipo de texturas se utiliza a menudo para modelar representaciones superficiales o volumétricas de elementos naturales como la madera, el mármol, el granito, el metal, la piedra y otros.\nAlgunos tipos de estás texturas son:\nTexturizado sólido: es un proceso en el que la función generadora de texturas se evalúa sobre R3 en cada punto de la superficie visible del modelo, de modo que las propiedades del material resultante (como el color, el brillo o la normalidad) sólo dependen de su posición en 3D, y no de su posición parametrizada en la superficie en 2D, como en el mapeo tradicional de texturas en 2D.\nTextura celular: esta textura se basa en puntos de características que están dispersos en un espacio tridimensional, puntos se utilizan para dividir el espacio en pequeñas regiones al azar llamadas celdas que suelen tener el aspecto de \u0026ldquo;escamas de lagarto\u0026rdquo; o \u0026ldquo;losas\u0026rdquo;. Aunque estas regiones son discretas, la propia función de base celular es continua y puede evaluarse en cualquier lugar del espacio. El ruido de Worley es un tipo común de textura celular.\nTexturas genéticas: es un enfoque experimental para generar texturas en la cual se modela el resultado final con ayuda de un usuario quien decide cuándo una textura es la adecuada. Como el resultado es difícil de controlar, este método se suele utilizar sólo para texturas experimentales o abstractas.\nTruchet Tiles # Son baldosas cuadradas decoradas con patrones que no son rotacionalmente simétricos. Cuando se colocan en un mosaico cuadrado del plano, pueden formar patrones variados, y la orientación de cada azulejo puede utilizarse para visualizar información asociada a la posición del azulejo dentro del mosaico.\nA continuación se presenta una fotografía de los azulejos de la Catedral Santa María de la Huerta de Tarazona, perteneciente a la entrada Simetrías I en la Catedral de Tarazona del blog MateTurismo, de Angel Requena.\nEn 1704, Sébastien Truchet estudió todos los posibles patrones formados por los triángulos rectos orientados en las cuatro esquinas de un cuadrado.\nEste tipo de patrones se han estudiado ampliamente y se han generalizado para incluir otros conjuntos de azulejos que no son rotacionalmente simétricos. En la siguiente imagen, se indica un mosaico Truchet tradicional, luego se indica un mosaico con diagonales y, finalmente, se indica cuartos de círculo, centrados alrededor de los vértices donde las diagonales solían tocarse (estos mosaicos, introducidos por Cyril Stanley Smith, crean interesantes patrones de caminos y círculos en forma de manchas).\nTexture Mapping # El mapeo de texturas es un método para añadir realismo a un gráfico generado por ordenador. Una imagen (la textura) se añade (mapea) a una forma más simple que se genera en la escena, como una calcomanía pegada a una superficie plana. Esto reduce la cantidad de computación necesaria para crear las formas y texturas en la escena. Por ejemplo, se puede generar una esfera y mapear una textura de cara, para eliminar la necesidad de procesar la forma de la nariz y los ojos.\nAlgunos tipos de mapeo de textura son los siguientes:\nMapeo difuso: es el tipo más común de mapeo de textura. Define el color y el patrón del objeto, es como pintar una imagen en la superficie del objeto.\nMapeo especular: se utilizan para definir el brillo/resplandor de una superficie. Normalmente, un mapa especular es una imagen en blanco y negro que mapea el valor de brillo en un objeto. Cuanto más blanco sea el píxel, más brillante será el objeto en ese lugar específico de la textura.\nMapeo de Oclusión Ambiental: es un mapa en escala de grises que contiene datos de iluminación. No se suele utilizar como mapa propio, sino que se suele combinar con el mapa difuso para crear sombras suaves. Mapeo Normal: es una técnica que permite dar iluminación y relieve más detallado a la superficie de un objeto. Este mapeo permite representar detalles de la superficie, como arrugas, arañazos y bordes biselados, almacenando las correspondientes normales de la superficie en una textura. CODE - Procedural Texturing # Para la realización del ejercicio, tuvimos en cuenta los patrones de The book of Shaders y el tutorial de ShaderToy - Truchet Tiling Explained [6].\nPara la implementación, la idea principal es dividir el shader con frag y crear los patrones, para lo cual se usó una función aleatoria. Luego se emplea como una textura dentro de un Cubo.\nSketch Code ... let pg; let theShader; function preload() { // shader adapted from here: https://thebookofshaders.com/09/ theShader = readShader(\u0026#39;/visual_computing_page/sketches/procedural_texturing.frag\u0026#39;, { matrices: Tree.NONE, varyings: Tree.NONE }); } function setup() { createCanvas(450, 450, WEBGL); // create frame buffer object to render the procedural texture pg = createGraphics(450, 450, WEBGL); option = createSelect(); option.position(12, 12); option.option(\u0026#34;Option 1\u0026#34;, 1); option.option(\u0026#34;Option 2\u0026#34;, 2); option.selected(\u0026#34;none\u0026#34;); option.changed(() =\u0026gt; { theShader.setUniform(\u0026#34;option\u0026#34;, option.value()); }); vel = createSlider(0, 1, 0.05, 0.05); vel.position(12, 40); vel.style(\u0026#34;width\u0026#34;, \u0026#34;280px\u0026#34;); textureMode(NORMAL); noStroke(); pg.noStroke(); pg.textureMode(NORMAL); // use theShader to render onto pg pg.shader(theShader); // emitResolution, see: // https://github.com/VisualComputing/p5.treegl#macros pg.emitResolution(theShader); // https://p5js.org/reference/#/p5.Shader/setUniform theShader.setUniform(\u0026#39;u_zoom\u0026#39;, 3); // pg clip-space quad (i.e., both x and y vertex coordinates ∈ [-1..1]) pg.quad(-1, -1, 1, -1, 1, 1, -1, 1); // set pg as texture texture(pg); } function draw() { background(33); orbitControl(); box(200, 200, 200); } function mouseMoved() { // https://p5js.org/reference/#/p5.Shader/setUniform theShader.setUniform(\u0026#39;u_zoom\u0026#39;, ((mouseX - width)/100)+5); theShader.setUniform(\u0026#39;u_rotater\u0026#39;, (mouseY - height/2)/50); theShader.setUniform(\u0026#39;vel\u0026#39;, vel.value()); // pg clip-space quad (i.e., both x and y vertex coordinates ∈ [-1..1]) pg.quad(-1, -1, 1, -1, 1, 1, -1, 1); } Fragment Shader ... #ifdef GL_ES precision mediump float; #endif uniform vec2 u_resolution; uniform float u_time, u_zoom, u_rotater, vel; uniform int option; vec2 brickTile(vec2 _st, float _zoom){ _st *= _zoom; // Here is where the offset is happening _st.x += step(1., mod(_st.y,2.0)) * 0.5; return fract(_st); } float box(vec2 _st, vec2 _size){ _size = vec2(0.5)-(u_zoom*0.05); vec2 uv = smoothstep(_size,_size+vec2(1e-4),_st); uv *= smoothstep(_size,_size+vec2(1e-4),vec2(1.0)-_st); return uv.x*uv.y; } float Hash21(vec2 p){ p=fract(p*vec2(264.34,435.345)); p+=dot(p,p+34.23); return fract(p.x*p.y); } void main(void){ if(option==2){ vec2 coord=gl_FragCoord.xy/u_resolution; vec3 color=vec3(0.0); coord+=u_time*vel; coord*=10.; vec2 gv=fract(coord)-.5; vec2 id=floor(coord); float n=Hash21(id); float width=.2; if(n\u0026lt;.5){ gv.x*=-1.; } float mask=smoothstep(.01,-.01,abs(gv.y+gv.x)-width); color+=mask; gl_FragColor=vec4(color,1.0); }else{ vec2 st = gl_FragCoord.xy/u_resolution.xy; vec3 color = vec3(0.0); // Modern metric brick of 215mm x 102.5mm x 65mm // http://www.jaharrison.me.uk/Brickwork/Sizes.html // st /= vec2(2.15,0.65)/1.5; // Apply the brick tiling st = brickTile(st,5.0); color = vec3(box(st,vec2(0.9))); gl_FragColor = vec4(color,1.0); } } Referencias # [1] https://en.wikipedia.org/wiki/Procedural_texture\n[2] https://en.wikipedia.org/wiki/Computer_graphics\n[3] https://culturacientifica.com/2022/04/20/el-arte-de-la-sencilla-baldosa-de-truchet/\n[4] https://en.wikipedia.org/wiki/Truchet_tiles\n[5] https://www.mathrecreation.com/2017/03/truchet-tiles.html\n[6] https://www.youtube.com/watch?v=2R7h76GoIJM\n[7] http://wedesignvirtual.com/what-does-a-specular-map-do/\n[8] https://docs.cryengine.com/display/SDKDOC2/Diffuse+Maps\n[9] https://askagamedev.tumblr.com/post/95739492476/could-you-explain-the-difference-between-bump\n[10] https://learnopengl.com/Advanced-Lighting/Normal-Mapping\n[11] https://docs.cryengine.com/display/SDKDOC2/Normal+Maps\n"}]